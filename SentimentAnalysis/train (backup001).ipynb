{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "0gr2-WoYLFNE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72fac1141c774ae8884c07b44045aeb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82c9261cc538457d8bcc02456e3f0972",
              "IPY_MODEL_60e9ab5bbfb84e58b931c7051af80687",
              "IPY_MODEL_e7eccb5bcba74c3baf2f8ac5da0cf151"
            ],
            "layout": "IPY_MODEL_9699deb123e545398d2dc46f76f7c003"
          }
        },
        "82c9261cc538457d8bcc02456e3f0972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8140fdd884914669abc6065e964545a1",
            "placeholder": "​",
            "style": "IPY_MODEL_58e7608d5a224fe2840ee020e9723e83",
            "value": "100%"
          }
        },
        "60e9ab5bbfb84e58b931c7051af80687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ca2b56a288b43318d23a60340b9d1b4",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d70b72e304174c81b4250303334e15ad",
            "value": 5
          }
        },
        "e7eccb5bcba74c3baf2f8ac5da0cf151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65a5c80ec3a8444ea315f879d85b40ab",
            "placeholder": "​",
            "style": "IPY_MODEL_655cd17463f04b01bb4e03084bbc076c",
            "value": " 5/5 [00:00&lt;00:00,  6.71ba/s]"
          }
        },
        "9699deb123e545398d2dc46f76f7c003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8140fdd884914669abc6065e964545a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58e7608d5a224fe2840ee020e9723e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ca2b56a288b43318d23a60340b9d1b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70b72e304174c81b4250303334e15ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65a5c80ec3a8444ea315f879d85b40ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "655cd17463f04b01bb4e03084bbc076c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5b299c8e5ef424981f8637acffafb33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73efd714db52450b969db3e059f3416d",
              "IPY_MODEL_836d36c139fb4e42b38063a51a6bdbcf",
              "IPY_MODEL_a3bac37217994c61a6d81de341269221"
            ],
            "layout": "IPY_MODEL_3f2c3933166f47f48cecd4a717a1c59e"
          }
        },
        "73efd714db52450b969db3e059f3416d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edc1b2ffe5214c91bc0a13825fccd139",
            "placeholder": "​",
            "style": "IPY_MODEL_7255d41b57844db6b0a931ed2219a2cb",
            "value": "100%"
          }
        },
        "836d36c139fb4e42b38063a51a6bdbcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8ef4da61ef649d5af8b55b15834bad0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a339398325d54da682b246c652efa1c9",
            "value": 1
          }
        },
        "a3bac37217994c61a6d81de341269221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2b479ee544e42a68de833159268eaa7",
            "placeholder": "​",
            "style": "IPY_MODEL_0ee16bef24974f73bd8177f81e7cb082",
            "value": " 1/1 [00:00&lt;00:00,  4.53ba/s]"
          }
        },
        "3f2c3933166f47f48cecd4a717a1c59e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc1b2ffe5214c91bc0a13825fccd139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7255d41b57844db6b0a931ed2219a2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8ef4da61ef649d5af8b55b15834bad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a339398325d54da682b246c652efa1c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2b479ee544e42a68de833159268eaa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee16bef24974f73bd8177f81e7cb082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### move & remote"
      ],
      "metadata": {
        "id": "TEbYZRG9FGdO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J3c1qj-5l56",
        "outputId": "d06fb01b-80dc-49b5-8b40-b0aff7a8c45d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/dailywave/SentimentAnalysis')\n",
        "print(\"현재 경로:\", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD-RLQg951lw",
        "outputId": "964e91b6-ff47-416a-ae4c-3968251695f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 경로: /content/drive/MyDrive/Colab Notebooks/dailywave/SentimentAnalysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pip"
      ],
      "metadata": {
        "id": "0gr2-WoYLFNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 설치\n",
        "!pip install emoji==2.2.0 \\\n",
        "matplotlib==3.6.2 \\\n",
        "numpy==1.23.5 \\\n",
        "pandas==1.5.2 \\\n",
        "soynlp==0.0.493 \\\n",
        "torch==1.13.0 --extra-index-url https://download.pytorch.org/whl/cu116 \\\n",
        "transformers==4.25.1 \\\n",
        "jupyter==1.0.0 \\\n",
        "ipykernel==6.19.2 \\\n",
        "datasets==2.7.1 \\\n",
        "tqdm==4.64.1 \\\n",
        "scikit-learn==1.2.0 \\\n",
        "emoji \\\n",
        "soynlp \\\n",
        "datasets"
      ],
      "metadata": {
        "id": "pgHZdgMNLGe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb61b879-6845-4a6c-8563-e688cd885b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Collecting emoji==2.2.0\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting matplotlib==3.6.2\n",
            "  Downloading matplotlib-3.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pandas==1.5.2\n",
            "  Downloading pandas-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting soynlp==0.0.493\n",
            "  Downloading soynlp-0.0.493-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting torch==1.13.0\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.0%2Bcu116-cp310-cp310-linux_x86_64.whl (1983.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m741.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.25.1\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter==1.0.0\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting ipykernel==6.19.2\n",
            "  Downloading ipykernel-6.19.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting datasets==2.7.1\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting tqdm==4.64.1\n",
            "  Downloading https://download.pytorch.org/whl/tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.2.0\n",
            "  Downloading scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.6.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.2) (2024.2)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from soynlp==0.0.493) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from soynlp==0.0.493) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0) (6.5.5)\n",
            "Collecting qtconsole (from jupyter==1.0.0)\n",
            "  Downloading qtconsole-5.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0) (7.16.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0) (7.7.1)\n",
            "Collecting comm>=0.1.1 (from ipykernel==6.19.2)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.19.2) (1.6.6)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.19.2) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.19.2) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.19.2) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.19.2) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.19.2) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.19.2) (6.3.3)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==6.19.2) (5.7.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.7.1) (17.0.0)\n",
            "Collecting dill<0.3.7 (from datasets==2.7.1)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting xxhash (from datasets==2.7.1)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.7.1)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.7.1) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.7.1) (3.10.10)\n",
            "Collecting responses<0.19 (from datasets==2.7.1)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.0) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.7.1) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.7.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.7.1) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.7.1) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.7.1) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.7.1) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.7.1) (4.0.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.19.2) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel==6.19.2)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.19.2) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.19.2) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.19.2) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.19.2) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.19.2) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel==6.19.2) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel==6.19.2) (5.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.6.2) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (2024.8.30)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0) (3.0.13)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.7.1)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (3.1.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0) (1.1.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0)\n",
            "  Downloading QtPy-2.4.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert->jupyter==1.0.0) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.19.2) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel==6.19.2) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.19.2) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel==6.19.2) (0.2.13)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.7.1) (0.2.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0) (2.6)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0) (1.2.2)\n",
            "Downloading matplotlib-3.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.8/416.8 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading ipykernel-6.19.2-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.1/145.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtconsole-5.6.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading QtPy-2.4.2-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234910 sha256=21d3a869dc39ca7fc2333ff76bf76996a48ac42bfb006c9054def46cdca7a012\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/3d/88/51a592b9ad17e7899126563698b4e3961983ebe85747228ba6\n",
            "Successfully built emoji\n",
            "Installing collected packages: tokenizers, xxhash, tqdm, torch, qtpy, numpy, jedi, emoji, dill, comm, responses, pandas, multiprocess, transformers, scikit-learn, matplotlib, ipykernel, soynlp, qtconsole, datasets, jupyter\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.6\n",
            "    Uninstalling tqdm-4.66.6:\n",
            "      Successfully uninstalled tqdm-4.66.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.2\n",
            "    Uninstalling scikit-learn-1.5.2:\n",
            "      Successfully uninstalled scikit-learn-1.5.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.8.0\n",
            "    Uninstalling matplotlib-3.8.0:\n",
            "      Successfully uninstalled matplotlib-3.8.0\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.25.0 requires matplotlib>=3.7.1, but you have matplotlib 3.6.2 which is incompatible.\n",
            "bigframes 1.25.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.25.0 requires pandas>=1.5.3, but you have pandas 1.5.2 which is incompatible.\n",
            "bigframes 1.25.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.2.0 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.2 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.19.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.2 which is incompatible.\n",
            "ibis-framework 9.2.0 requires pandas<3,>=1.5.3, but you have pandas 1.5.2 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.2 which is incompatible.\n",
            "plotnine 0.14.0 requires matplotlib>=3.8.0, but you have matplotlib 3.6.2 which is incompatible.\n",
            "plotnine 0.14.0 requires pandas>=2.2.0, but you have pandas 1.5.2 which is incompatible.\n",
            "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 1.13.0+cu116 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 1.13.0+cu116 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed comm-0.2.2 datasets-2.7.1 dill-0.3.6 emoji-2.2.0 ipykernel-6.19.2 jedi-0.19.1 jupyter-1.0.0 matplotlib-3.6.2 multiprocess-0.70.14 numpy-1.23.5 pandas-1.5.2 qtconsole-5.6.1 qtpy-2.4.2 responses-0.18.0 scikit-learn-1.2.0 soynlp-0.0.493 tokenizers-0.13.3 torch-1.13.0+cu116 tqdm-4.64.1 transformers-4.25.1 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "f4f617fd4c4243e48590a6d247f5fd03"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import emoji\n",
        "# import matplotlib\n",
        "# import numpy\n",
        "# import pandas\n",
        "# import soynlp\n",
        "# import torch\n",
        "# import transformers\n",
        "# import jupyter\n",
        "# import ipykernel\n",
        "# import datasets\n",
        "# import tqdm\n",
        "# import sklearn\n",
        "\n",
        "# print(\"emoji 버전:\", emoji.__version__)\n",
        "# print(\"matplotlib 버전:\", matplotlib.__version__)\n",
        "# print(\"numpy 버전:\", numpy.__version__)\n",
        "# print(\"pandas 버전:\", pandas.__version__)\n",
        "# print(\"soynlp 버전:\", soynlp.__version__)\n",
        "# print(\"torch 버전:\", torch.__version__)\n",
        "# print(\"transformers 버전:\", transformers.__version__)\n",
        "# print(\"jupyter 버전:\", jupyter.__version__)\n",
        "# print(\"ipykernel 버전:\", ipykernel.__version__)\n",
        "# print(\"datasets 버전:\", datasets.__version__)\n",
        "# print(\"tqdm 버전:\", tqdm.__version__)\n",
        "# print(\"scikit-learn 버전:\", sklearn.__version__)\n"
      ],
      "metadata": {
        "id": "y-Vfjw8CLNg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### utils"
      ],
      "metadata": {
        "id": "wEORuVy49KQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import emoji\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from soynlp.normalizer import repeat_normalize\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "from transformers import EvalPrediction\n",
        "\n",
        "def test_util():\n",
        "  print(\"utils avilable\")\n",
        "\n",
        "def clean(text):\n",
        "    pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣]+')\n",
        "    url_pattern = re.compile(\n",
        "        r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
        "    text = pattern.sub(' ', text)\n",
        "    text = emoji.replace_emoji(text, replace='') #emoji 삭제\n",
        "    text = url_pattern.sub('', text)\n",
        "    text = text.strip()\n",
        "    text = repeat_normalize(text, num_repeats=2)\n",
        "\n",
        "    return text\n",
        "\n",
        "def make_current_datetime_dir(path):\n",
        "    now = datetime.now().strftime(r'%Y%m%dT%H-%M-%S')\n",
        "    make_dir_path = os.path.join(path, now)\n",
        "    os.mkdir(make_dir_path)\n",
        "\n",
        "    return make_dir_path\n",
        "\n",
        "\n",
        "def preprocess_data(examples, tokenizer, labels):\n",
        "    # take a batch of texts\n",
        "    sentences = [clean(sentence) for sentence in examples['document']]  # KcELECTRA 사전 학습시 사용한 정제 적용\n",
        "\n",
        "    # encode them\n",
        "    # encoding = tokenizer(sentences, padding='max_length', truncation=True, max_length=80)\n",
        "\n",
        "    '''\n",
        "    Trainer에서 data_collector 사용으로\n",
        "    padding, max_length 옵션을 지정해주지 않아도됨.\n",
        "    data_collector에서 각 미니 배치에 포함된 sequence 중 가장 긴 sequence를 기준으로 나머지 문장을 padding 함\n",
        "    '''\n",
        "    encoding = tokenizer(sentences, truncation=True)\n",
        "\n",
        "    # add labels\n",
        "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
        "\n",
        "    # create numpy array of shape (batch_size, num_labels)\n",
        "    labels_matrix = np.zeros((len(sentences), len(labels)))\n",
        "\n",
        "    # fill numpy array\n",
        "    for idx, label in enumerate(labels):\n",
        "        labels_matrix[:, idx] = labels_batch[label]\n",
        "\n",
        "    encoding['labels'] = labels_matrix.tolist()\n",
        "\n",
        "    return encoding\n",
        "\n",
        "\n",
        "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    pre = precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    rec = recall_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # return as dictionary\n",
        "    metrics = {'pre': pre,\n",
        "               'rec': rec,\n",
        "               'f1': f1_micro_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'accuracy': accuracy}\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    print(\"Calculating metrics...\")\n",
        "    preds = p.predictions[0] if isinstance(p.predictions,\n",
        "            tuple) else p.predictions\n",
        "    result = multi_label_metrics(\n",
        "        predictions=preds,\n",
        "        labels=p.label_ids)\n",
        "    return result\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  print(\"utils\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tau28nlE8RoO",
        "outputId": "63a3c0c3-d3f5-428c-d3a4-07d252f20c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-05 08:19:58.245930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-05 08:19:58.281717: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-05 08:19:58.305265: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-05 08:19:58.396330: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-05 08:20:06.197282: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### constants"
      ],
      "metadata": {
        "id": "PQCvZZUFCtuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#EDC\n",
        "ID2LABEL_KOR = {0: '기쁨',\n",
        "        1: '당황',\n",
        "        2: '분노',\n",
        "        3: '불안',\n",
        "        4: '상처',\n",
        "        5: '슬픔',\n",
        "        }\n",
        "\n",
        "ID2LABEL_EN = {0: 'joy',\n",
        "                1: 'embarrassed',\n",
        "                2: 'anger',\n",
        "                3: 'nervous',\n",
        "                4: 'hurt',\n",
        "                5: 'sad',\n",
        "                }\n",
        "#------------------------------\n",
        "# # DVforEC(5)\n",
        "# ID2LABEL_KOR = {0: '분노',\n",
        "#         1: '역겨움',\n",
        "#         2: '공포',\n",
        "#         3: '행복',\n",
        "#         4: '중립',\n",
        "#         5: '슬픔',\n",
        "#         6: '놀람',\n",
        "#         }\n",
        "\n",
        "# ID2LABEL_EN = {0: 'Angry',\n",
        "#                 1: 'Disgust',\n",
        "#                 2: 'Fear',\n",
        "#                 3: 'Happiness',\n",
        "#                 4: 'Neutral',\n",
        "#                 5: 'Sadness',\n",
        "#                 6: 'Surpise'\n",
        "#                 }\n",
        "#------------------------------\n",
        "# # DVforEC(4_8l)\n",
        "# ID2LABEL_KOR = {0: '분노',\n",
        "#         1: '슬픔',\n",
        "#         2: '불안',\n",
        "#         3: '상처',\n",
        "#         4: '당황',\n",
        "#         5: '기쁨',\n",
        "#         6: '감사',\n",
        "#         7: '평온'\n",
        "#         }\n",
        "\n",
        "# ID2LABEL_EN = {0: 'Angry',\n",
        "#                 1: 'Sadness',\n",
        "#                 2: 'Fear',\n",
        "#                 3: 'Hurt',\n",
        "#                 4: 'embarrassed',\n",
        "#                 5: 'Happiness',\n",
        "#                 6: 'Thankful',\n",
        "#                 7 : 'Peaceful'\n",
        "#                 }\n"
      ],
      "metadata": {
        "id": "WpZDfg6BCwwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "aJNc86-C9OiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/dailywave/SentimentAnalysis')\n",
        "\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding\n",
        "from transformers import TrainingArguments, Trainer, logging\n",
        "\n",
        "current_path = os.getcwd()\n",
        "print(\"현재 경로:\", current_path)\n",
        "test_util()\n",
        "print(ID2LABEL_EN)"
      ],
      "metadata": {
        "id": "zVV9bVoW9rWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8409c082-4912-4bd0-d044-265f4169dd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 경로: /content/drive/MyDrive/Colab Notebooks/dailywave/SentimentAnalysis\n",
            "utils avilable\n",
            "{0: 'joy', 1: 'embarrassed', 2: 'anger', 3: 'nervous', 4: 'hurt', 5: 'sad'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# GPU 디바이스 설정\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f'Using device: {device}')\n"
      ],
      "metadata": {
        "id": "jK1fj_1fFnj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd6970b-ddbe-4889-ebb7-b283016b74a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "def train(opt):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(opt['pretrained_tokenizer'])\n",
        "    id2label = ID2LABEL_EN\n",
        "    label2id = {v: k for k, v in id2label.items()}\n",
        "    labels = list(label2id.keys())\n",
        "    # dataset = load_dataset('csv', data_files={'train': opt['train_dataset_path'],\n",
        "    #                                           'val': opt['val_dataset_path']\n",
        "    #                                           }\n",
        "    #                        )\n",
        "    # dataset = dataset.map(preprocess_data,\n",
        "    #                               batched=True,\n",
        "    #                               remove_columns=dataset['train'].column_names,\n",
        "    #                               fn_kwargs={'tokenizer': tokenizer,\n",
        "    #                                          'labels': labels\n",
        "    #                                          }\n",
        "    #                               )\n",
        "\n",
        "    # 로컬 CSV 파일 로드\n",
        "    train_df = pd.read_csv(opt['train_dataset_path'], dtype=str)  # 모든 열을 문자열로 로드\n",
        "    val_df = pd.read_csv(opt['val_dataset_path'], dtype=str)\n",
        "\n",
        "    print('val_df',train_df[0:1])\n",
        "\n",
        "    # 데이터 타입을 확인\n",
        "    print(train_df.dtypes)\n",
        "    print(val_df.dtypes)\n",
        "\n",
        "    # DataFrame을 Hugging Face Dataset으로 변환\n",
        "    train_dataset = Dataset.from_pandas(train_df)\n",
        "    val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "    # 데이터셋 합치기\n",
        "    dataset = DatasetDict({\n",
        "        'train': train_dataset,\n",
        "        'val': val_dataset\n",
        "    })\n",
        "\n",
        "    # 데이터 전처리\n",
        "    dataset = dataset.map(\n",
        "        preprocess_data,\n",
        "        batched=True,\n",
        "        remove_columns=dataset['train'].column_names,\n",
        "        fn_kwargs={'tokenizer': tokenizer, 'labels': labels}\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    dataset.set_format('torch')\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(opt['pretrained_model'],\n",
        "                                                            problem_type=opt['problem_type'],\n",
        "                                                            num_labels=len(labels),\n",
        "                                                            id2label=id2label,\n",
        "                                                            label2id=label2id)\n",
        "    args = TrainingArguments(output_dir=make_current_datetime_dir(opt['output_dir']),\n",
        "                            evaluation_strategy=opt['evaluation_strategy'],\n",
        "                            save_strategy=opt['save_strategy'],\n",
        "                            learning_rate=opt['learning_rate'],\n",
        "                            per_device_train_batch_size=opt['per_device_train_batch_size'],\n",
        "                            per_device_eval_batch_size=opt['per_device_eval_batch_size'],\n",
        "                            num_train_epochs=opt['num_train_epochs'],\n",
        "                            weight_decay=opt['weight_decay'],\n",
        "                            load_best_model_at_end=opt['load_best_model_at_end'],\n",
        "                            metric_for_best_model=opt['metric_for_best_model'],\n",
        "                            seed=opt['seed'],\n",
        "                            dataloader_num_workers=opt['dataloader_num_workers'],\n",
        "                            no_cuda=opt['no_cuda']\n",
        "                            )\n",
        "    trainer = Trainer(args=args,\n",
        "                      model=model,\n",
        "                      tokenizer=tokenizer,\n",
        "                      train_dataset=dataset['train'],\n",
        "                      eval_dataset=dataset['val'],\n",
        "                      compute_metrics=compute_metrics,\n",
        "                      data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "                      )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    opt = {'pretrained_model': 'beomi/KcELECTRA-base-v2022',\n",
        "           'pretrained_tokenizer': 'beomi/KcELECTRA-base-v2022',\n",
        "           'problem_type': 'multi_label_classification',\n",
        "           'train_dataset_path': './data/preprocess/EDC_train.csv', #train data\n",
        "           'val_dataset_path': './data/preprocess/EDC_val.csv', # val data\n",
        "           'output_dir': './weights/',\n",
        "           'metric_for_best_model': 'f1',\n",
        "           'evaluation_strategy': 'steps',\n",
        "           'save_strategy': 'steps',\n",
        "           'eval_steps': 500,\n",
        "           'seed': 1031,\n",
        "           'no_cuda': False,\n",
        "           'learning_rate': 1e-5,\n",
        "           'per_device_train_batch_size': 16,\n",
        "           'per_device_eval_batch_size': 16,\n",
        "           'num_train_epochs': 10,\n",
        "           'weight_decay': 0.01,\n",
        "           'dataloader_num_workers': 4,\n",
        "           'load_best_model_at_end': False,\n",
        "           }\n",
        "\n",
        "    train(opt)\n",
        "    print(\"train complete\")"
      ],
      "metadata": {
        "id": "t0j4lrBb6WVP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "72fac1141c774ae8884c07b44045aeb1",
            "82c9261cc538457d8bcc02456e3f0972",
            "60e9ab5bbfb84e58b931c7051af80687",
            "e7eccb5bcba74c3baf2f8ac5da0cf151",
            "9699deb123e545398d2dc46f76f7c003",
            "8140fdd884914669abc6065e964545a1",
            "58e7608d5a224fe2840ee020e9723e83",
            "5ca2b56a288b43318d23a60340b9d1b4",
            "d70b72e304174c81b4250303334e15ad",
            "65a5c80ec3a8444ea315f879d85b40ab",
            "655cd17463f04b01bb4e03084bbc076c",
            "d5b299c8e5ef424981f8637acffafb33",
            "73efd714db52450b969db3e059f3416d",
            "836d36c139fb4e42b38063a51a6bdbcf",
            "a3bac37217994c61a6d81de341269221",
            "3f2c3933166f47f48cecd4a717a1c59e",
            "edc1b2ffe5214c91bc0a13825fccd139",
            "7255d41b57844db6b0a931ed2219a2cb",
            "b8ef4da61ef649d5af8b55b15834bad0",
            "a339398325d54da682b246c652efa1c9",
            "b2b479ee544e42a68de833159268eaa7",
            "0ee16bef24974f73bd8177f81e7cb082"
          ]
        },
        "outputId": "27304c50-c487-4b90-fa15-c502aa21fcf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_df   label                                           document joy embarrassed  \\\n",
            "0     5  내가 몸이 아파보니까 이렇게 힘든데 다른 사람들이 아팠을 땐 왜 신경을 써주지 못했...   0           0   \n",
            "\n",
            "  anger nervous hurt sad  \n",
            "0     0       0    0   1  \n",
            "label          object\n",
            "document       object\n",
            "joy            object\n",
            "embarrassed    object\n",
            "anger          object\n",
            "nervous        object\n",
            "hurt           object\n",
            "sad            object\n",
            "dtype: object\n",
            "label          object\n",
            "document       object\n",
            "joy            object\n",
            "embarrassed    object\n",
            "anger          object\n",
            "nervous        object\n",
            "hurt           object\n",
            "sad            object\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72fac1141c774ae8884c07b44045aeb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5b299c8e5ef424981f8637acffafb33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 4648\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2910\n",
            "  Number of trainable parameters = 127781382\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 996\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.4104, 'learning_rate': 8.281786941580758e-06, 'epoch': 1.72}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./weights/20241105T08-20-36/checkpoint-500\n",
            "Configuration saved in ./weights/20241105T08-20-36/checkpoint-500/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating metrics...\n",
            "{'eval_loss': 0.31987741589546204, 'eval_pre': 0.8292079207920792, 'eval_rec': 0.33634538152610444, 'eval_f1': 0.47857142857142854, 'eval_roc_auc': 0.6612449799196787, 'eval_accuracy': 0.33634538152610444, 'eval_runtime': 2.1874, 'eval_samples_per_second': 455.333, 'eval_steps_per_second': 28.801, 'epoch': 1.72}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in ./weights/20241105T08-20-36/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./weights/20241105T08-20-36/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./weights/20241105T08-20-36/checkpoint-500/special_tokens_map.json\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e52f9deb2e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1430, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1877/3518169766.py\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m            }\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_1877/3518169766.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     84\u001b[0m                       )\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         )\n\u001b[0;32m-> 1527\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1840\u001b[0m                         \u001b[0moptimizer_was_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_before\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mscale_after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0moptimizer_was_run\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "r-wDJLk8zyBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from transformers import DataCollatorWithPadding, logging\n",
        "from tqdm import tqdm\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'\n",
        "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(opt):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(opt['ckpt_path'])\n",
        "    # dataset = load_dataset('csv', data_files={'test': opt['test_dataset_path']})\n",
        "\n",
        "     # 로컬 CSV 파일 로드\n",
        "    test_df = pd.read_csv(opt['test_dataset_path'], dtype=str)  # 모든 열을 문자열로 로드\n",
        "    # test_df.rename(columns={'document': 'sentence'}, inplace=True)\n",
        "\n",
        "\n",
        "    # 데이터 타입을 확인\n",
        "    print(test_df.dtypes)\n",
        "\n",
        "    # DataFrame을 Hugging Face Dataset으로 변환\n",
        "    train_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "    # 데이터셋 합치기\n",
        "    dataset = DatasetDict({\n",
        "        'test': train_dataset\n",
        "    })\n",
        "\n",
        "    dataset = dataset.map(preprocess_data,\n",
        "                                  batched=True,\n",
        "                                  remove_columns=dataset['test'].column_names,\n",
        "                                  fn_kwargs={'tokenizer': tokenizer,\n",
        "                                             'labels': list(ID2LABEL_EN.values())\n",
        "                                             }\n",
        "                                  )\n",
        "    dataset.set_format('torch')\n",
        "    dataloader = torch.utils.data.DataLoader(dataset['test'],\n",
        "                                             batch_size=opt['batch_size'],\n",
        "                                             shuffle=False,\n",
        "                                             num_workers=opt['num_workers'],\n",
        "                                             collate_fn=DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "                                             )\n",
        "\n",
        "    scores = {'micro_f1': [],\n",
        "            'roc_auc': [],\n",
        "            'accuracy': []\n",
        "            }\n",
        "    device = torch.device(opt['device'])\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(opt['ckpt_path']).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    for data in tqdm(dataloader, total=len(dataloader), ncols=100):\n",
        "        inputs = {'input_ids': data['input_ids'].to(device),\n",
        "                    'token_type_ids': data['token_type_ids'].to(device),\n",
        "                    'attention_mask': data['attention_mask'].to(device)}\n",
        "        labels = data['labels']\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits.detach().cpu()\n",
        "\n",
        "        score = multi_label_metrics(logits, labels)\n",
        "        scores['micro_f1'].append(score['f1'])\n",
        "        scores['roc_auc'].append(score['roc_auc'])\n",
        "        scores['accuracy'].append(score['accuracy'])\n",
        "\n",
        "    micro_f1 = np.mean(scores['micro_f1'])\n",
        "    roc_auc = np.mean(scores['roc_auc'])\n",
        "    accuracy = np.mean(scores['accuracy'])\n",
        "    print(f'micro_f1: {micro_f1:.4f}, roc_acu: {roc_auc:.4f}, accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    opt = {'ckpt_path': './weights/20241031T10-30-48/checkpoint-12500',\n",
        "           'test_dataset_path': './data/preprocess/DVforEC(5)_test.csv',\n",
        "           'device': 'cuda:0',\n",
        "           'batch_size': 64,\n",
        "           'num_workers': 4,\n",
        "           }\n",
        "\n",
        "    evaluate(opt)"
      ],
      "metadata": {
        "id": "KSkETG53z0go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test & record result on csv"
      ],
      "metadata": {
        "id": "3C5461t2YhcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from transformers import DataCollatorWithPadding, logging\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'\n",
        "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "def evaluate(opt):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(opt['ckpt_path'])\n",
        "    test_df = pd.read_csv(opt['test_dataset_path'], dtype=str)\n",
        "\n",
        "    # DataFrame을 Hugging Face Dataset으로 변환\n",
        "    train_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "    # 데이터셋 합치기\n",
        "    dataset = DatasetDict({\n",
        "        'test': train_dataset\n",
        "    })\n",
        "\n",
        "    dataset = dataset.map(preprocess_data,\n",
        "                          batched=True,\n",
        "                          remove_columns=dataset['test'].column_names,\n",
        "                          fn_kwargs={'tokenizer': tokenizer,\n",
        "                                     'labels': list(ID2LABEL_EN.values())}\n",
        "                          )\n",
        "    dataset.set_format('torch')\n",
        "    dataloader = torch.utils.data.DataLoader(dataset['test'],\n",
        "                                             batch_size=opt['batch_size'],\n",
        "                                             shuffle=False,\n",
        "                                             num_workers=opt['num_workers'],\n",
        "                                             collate_fn=DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "                                             )\n",
        "\n",
        "    device = torch.device(opt['device'])\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(opt['ckpt_path']).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    results = []\n",
        "    for data in tqdm(dataloader, total=len(dataloader), ncols=100):\n",
        "        inputs = {'input_ids': data['input_ids'].to(device),\n",
        "                  'token_type_ids': data['token_type_ids'].to(device),\n",
        "                  'attention_mask': data['attention_mask'].to(device)}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits.detach().cpu()\n",
        "\n",
        "        # 가장 높은 점수의 감정 예측\n",
        "        predictions = logits.argmax(dim=-1).numpy()\n",
        "        results.extend(predictions)\n",
        "\n",
        "    # 예측 결과를 DataFrame에 추가하고 필요한 열만 남기기\n",
        "    test_df['result'] = results\n",
        "    test_df = test_df[['label', 'document', 'result']]\n",
        "\n",
        "    # label과 result 비교하여 ans 열 추가\n",
        "    test_df['ans'] = test_df.apply(lambda x: 'T' if x['label'] == str(x['result']) else 'F', axis=1)\n",
        "\n",
        "    # 숫자 데이터를 문자열로 바꾸기\n",
        "    emotion_map = { '0': 'Angry', '1': 'Sadness', '2': 'Fear', '3': 'Hurt','4': 'embarrassed', '5': 'Happiness', '6': 'Thankful', '7': 'Peaceful'}\n",
        "    test_df['result'] = test_df['result'].astype(str).map(emotion_map)\n",
        "    test_df['label'] = test_df['label'].astype(str).map(emotion_map)\n",
        "\n",
        "    # 수정된 DataFrame을 파일에 저장\n",
        "    result_file = './data/result/DVforEC(4_8l)-001_test_result.csv'\n",
        "    test_df.to_csv(result_file, index=False,encoding='utf-8-sig')\n",
        "    print(f\"Updated {result_file} with ans column\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    opt = {'ckpt_path': './weights/20241031T10-30-48/checkpoint-12500',\n",
        "           'test_dataset_path': './data/preprocess/EDC_test.csv',\n",
        "           'device': 'cuda:0',\n",
        "           'batch_size': 64,\n",
        "           'num_workers': 4,\n",
        "           }\n",
        "\n",
        "    evaluate(opt)\n"
      ],
      "metadata": {
        "id": "iJCrtw_OWkk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## predict"
      ],
      "metadata": {
        "id": "mFmwSVXB6u_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "def infer(sentences):\n",
        "    global model\n",
        "    global tokenizer\n",
        "    global device\n",
        "    id2label = ID2LABEL_KOR\n",
        "    results = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = clean(sentence)\n",
        "\n",
        "        infer_stime = time.time()\n",
        "        encoding = tokenizer(sentence, return_tensors='pt').to(device)\n",
        "        outputs = model(**encoding)\n",
        "        logits = outputs.logits\n",
        "        sigmoid = torch.nn.Sigmoid()\n",
        "        preds = sigmoid(logits.squeeze())\n",
        "        infer_etime = time.time()\n",
        "\n",
        "        result = {'문장': sentence,\n",
        "                  '추론시간': infer_etime - infer_stime\n",
        "                  }\n",
        "\n",
        "        # 가장 높은 수치를 가진 라벨 찾기\n",
        "        max_prob_idx = torch.argmax(preds).item()\n",
        "        result['추론 감정'] = id2label[max_prob_idx]  # 해당 인덱스의 라벨을 가져옴\n",
        "\n",
        "        for id, label in id2label.items():\n",
        "            prob = preds[id].item()\n",
        "            result[label] = prob\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "    results = pd.DataFrame(results)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ckpt_path = './weights/20241031T10-30-48/checkpoint-12500'\n",
        "    device = 'cuda:0'\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(ckpt_path).to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(ckpt_path)\n",
        "\n",
        "    sentences = ['아내가 회사에서 잘렸어.']\n",
        "\n",
        "    model.eval()\n",
        "    ret = infer(sentences)\n",
        "    print(ret.T)\n"
      ],
      "metadata": {
        "id": "DpJ_cL1-6wla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rn-YwYVl7Alq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}